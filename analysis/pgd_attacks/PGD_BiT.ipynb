{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGD_BiT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/sayakpaul/robustness-vit/blob/main/BiT/PGD_BiT.ipynb",
      "authorship_tag": "ABX9TyOa6AWomZejOY3+PoKkZxpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/robustness-vit/blob/main/BiT/PGD_BiT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J_QRc2HT-Iw"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OJCvq1Z-lTP",
        "outputId": "396ba6aa-6578-44c1-a3a9-f85bd9d12633"
      },
      "source": [
        "!gdown --id 1QtAJsTjBOf3CnrTzTTqP-nPnHcTc2g9E\n",
        "!tar xf val.tar\n",
        "!rm -rf val.tar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QtAJsTjBOf3CnrTzTTqP-nPnHcTc2g9E\n",
            "To: /content/val.tar\n",
            "6.75GB [01:13, 91.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOY8gBl0AfKv",
        "outputId": "c163d449-da4e-455a-c3d2-f9b72cb4c34b"
      },
      "source": [
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
        "!gdown --id 1Wbn3yuBBR2KO8OEI38YkHYNu2mQ96E7N"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-12 05:48:47--  https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.119.128, 108.177.126.128, 108.177.127.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35363 (35K) [application/json]\n",
            "Saving to: ‘imagenet_class_index.json’\n",
            "\n",
            "imagenet_class_inde 100%[===================>]  34.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-12 05:48:52 (154 MB/s) - ‘imagenet_class_index.json’ saved [35363/35363]\n",
            "\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wbn3yuBBR2KO8OEI38YkHYNu2mQ96E7N\n",
            "To: /content/random_hundred_paths_val.npy\n",
            "100% 16.9k/16.9k [00:00<00:00, 7.73MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxKW6h11-4UF"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJxftbnLAHHB"
      },
      "source": [
        "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
        "    imagenet_labels = json.load(read_file)\n",
        "    \n",
        "MAPPING_DICT = {}\n",
        "LABEL_NAMES = {}\n",
        "for label_id in list(imagenet_labels.keys()):\n",
        "    MAPPING_DICT[imagenet_labels[label_id][0]] = int(label_id)\n",
        "    LABEL_NAMES[int(label_id)] = imagenet_labels[label_id][1]\n",
        "    \n",
        "HUNDRED_PATHS = HUNDRED_PATHS = np.load(\"random_hundred_paths_val.npy\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5A7EPwCUA3R"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "885d0CrPASzI"
      },
      "source": [
        "EPS = [0.001, 0.002, 0.003]\n",
        "ITERATIONS = 10\n",
        "RESIZE = 224"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtgQ2g2KAv6j"
      },
      "source": [
        "# Function to preprocess an image for performing inference\n",
        "def preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image)\n",
        "    if image.shape[-1] == 1:\n",
        "        image = tf.tile(image, [1, 1, 3])\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, (RESIZE, RESIZE))\n",
        "    image = tf.expand_dims(image, 0)\n",
        "\n",
        "    class_idx = MAPPING_DICT[image_path.split(\"/\")[1]]\n",
        "    class_label = LABEL_NAMES[class_idx]\n",
        "    return image, class_idx, class_label\n",
        "\n",
        "# Clipping utility to project delta \n",
        "def clip_eps(delta_tensor):\n",
        "    return tf.clip_by_value(delta_tensor, \n",
        "                            clip_value_min=-EPS[0], \n",
        "                            clip_value_max=EPS[0])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_z-kwsIBjsb"
      },
      "source": [
        "# m-r101x3 because it's somewhat comparable to ViT_L-16\n",
        "BIT_URL = \"https://tfhub.dev/google/bit/m-r101x3/ilsvrc2012_classification/1\"\n",
        "bit_module = tf.keras.Sequential([hub.KerasLayer(BIT_URL)])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhpNKpnwUEuP"
      },
      "source": [
        "## Attack Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA_hR-RJBvzS"
      },
      "source": [
        "def generate_adversaries(image, delta, model, true_class_index):\n",
        "    # Loss and optimizer\n",
        "    scc_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    losses = []\n",
        "\n",
        "    for t in range(ITERATIONS):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(delta)\n",
        "            inp = tf.clip_by_value(image + delta, 0, 1)\n",
        "            predictions = model(inp, training=False)\n",
        "            loss = - scc_loss(\n",
        "                    tf.convert_to_tensor([true_class_index]),\n",
        "                    predictions\n",
        "                )\n",
        "            \n",
        "        # Get the gradients\n",
        "        gradients = tape.gradient(loss, delta)\n",
        "        \n",
        "        # Update the weights\n",
        "        optimizer.apply_gradients([(gradients, delta)])\n",
        "\n",
        "        # Project the delta back (l-infinite norm)\n",
        "        delta.assign_add(clip_eps(delta))\n",
        "        losses.append(loss)\n",
        "\n",
        "    return delta, losses"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCBu3N6yFg7L"
      },
      "source": [
        "def show_image(images, labels, original_label, filename):\n",
        "    fig, ax = plt.subplots(ncols=3, figsize=(10, 10))\n",
        "    ax[0].set_title(\"Input Image \\n\"\n",
        "        f\"Original Label: {original_label}\\n\"\n",
        "        f\"Prediction: {labels[0]}\")\n",
        "    ax[0].imshow(tf.squeeze(images[0], 0))\n",
        "\n",
        "    ax[1].set_title(r\"$\\delta$ (Zoomed in)\")\n",
        "    ax[1].imshow(tf.squeeze(images[1], 0))\n",
        "\n",
        "    ax[2].set_title(\"Perturbed Image \\n\"\n",
        "        f\"Prediction: {labels[1]}\")\n",
        "    ax[2].imshow(tf.squeeze(images[2], 0))\n",
        "\n",
        "    ax[0].axis(\"off\")\n",
        "    ax[1].axis(\"off\")\n",
        "    ax[2].axis(\"off\")\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    fig.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
        "    plt.close(\"all\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndyfZjRTCvZt"
      },
      "source": [
        "def perturb_image(image_path, model):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    preprocessed_image, true_class_index, class_label = preprocess_image(image_path)\n",
        "    image_idx = image_path.split(\".\")[0].split(\"_\")[-1]\n",
        "    print(\"Original label:\", class_label)\n",
        "\n",
        "    # Generate predictions before any adversaries\n",
        "    initial_pred = model.predict(preprocessed_image)\n",
        "    print(\"Prediction before adv.:\", LABEL_NAMES[initial_pred.argmax()])\n",
        "\n",
        "    # Initialize the perturbation quantity\n",
        "    image_tensor = tf.constant(preprocessed_image, dtype=tf.float32)\n",
        "    delta = tf.Variable(tf.zeros_like(image_tensor), trainable=True)\n",
        "\n",
        "    # Get the learned delta \n",
        "    delta_tensor, losses = generate_adversaries(image_tensor, delta, \n",
        "                                                model, true_class_index)\n",
        "\n",
        "    # Pertubed image\n",
        "    pertubed_image = (image_tensor + delta_tensor)\n",
        "    pertubed_image = tf.clip_by_value(pertubed_image, 0, 1)\n",
        "\n",
        "    # Generate prediction\n",
        "    adv_pred = model.predict(pertubed_image)\n",
        "    print(\"Prediction after adv.:\", LABEL_NAMES[adv_pred.argmax()])\n",
        "\n",
        "    images.append(preprocessed_image)\n",
        "    images.append(tf.clip_by_value(50*delta_tensor.numpy()+0.5, 0, 1))\n",
        "    images.append(pertubed_image)\n",
        "    labels.append(LABEL_NAMES[initial_pred.argmax()])\n",
        "    labels.append(LABEL_NAMES[adv_pred.argmax()])\n",
        "    show_image(images, labels, class_label, f\"{image_idx}_bit.png\")\n",
        "\n",
        "    return LABEL_NAMES[initial_pred.argmax()], LABEL_NAMES[adv_pred.argmax()], losses"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXmakya8UHpJ"
      },
      "source": [
        "## Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7FalOhmEAEO",
        "outputId": "1a4b24f4-0458-406f-bd98-099e80bc82fa"
      },
      "source": [
        "num_corrects = 0\n",
        "adv_attacks = 0\n",
        "all_losses = []\n",
        "\n",
        "for i, image_path in enumerate(HUNDRED_PATHS):\n",
        "    pred_label, adv_label, losses = perturb_image(image_path, bit_module)\n",
        "\n",
        "    class_idx = MAPPING_DICT[image_path.split(\"/\")[1]]\n",
        "    class_label = LABEL_NAMES[class_idx]\n",
        "\n",
        "    if class_label == pred_label:\n",
        "        print(f\"================{i}================\")\n",
        "        all_losses.append(losses)\n",
        "        num_corrects += 1\n",
        "        if pred_label != adv_label:\n",
        "            adv_attacks += 1\n",
        "\n",
        "print(f\"Total correct predictions: {num_corrects}\")\n",
        "print(f\"Total successful attacks: {adv_attacks}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original label: bow\n",
            "Prediction before adv.: croquet_ball\n",
            "Prediction after adv.: croquet_ball\n",
            "Original label: Komodo_dragon\n",
            "Prediction before adv.: Komodo_dragon\n",
            "Prediction after adv.: sea_lion\n",
            "================1================\n",
            "Original label: harvester\n",
            "Prediction before adv.: thresher\n",
            "Prediction after adv.: thresher\n",
            "Original label: langur\n",
            "Prediction before adv.: langur\n",
            "Prediction after adv.: coffee_mug\n",
            "================3================\n",
            "Original label: patio\n",
            "Prediction before adv.: patio\n",
            "Prediction after adv.: park_bench\n",
            "================4================\n",
            "Original label: speedboat\n",
            "Prediction before adv.: speedboat\n",
            "Prediction after adv.: canoe\n",
            "================5================\n",
            "Original label: jack-o'-lantern\n",
            "Prediction before adv.: jack-o'-lantern\n",
            "Prediction after adv.: television\n",
            "================6================\n",
            "Original label: go-kart\n",
            "Prediction before adv.: go-kart\n",
            "Prediction after adv.: racer\n",
            "================7================\n",
            "Original label: purse\n",
            "Prediction before adv.: wool\n",
            "Prediction after adv.: wool\n",
            "Original label: Dutch_oven\n",
            "Prediction before adv.: Dutch_oven\n",
            "Prediction after adv.: stove\n",
            "================9================\n",
            "Original label: water_bottle\n",
            "Prediction before adv.: water_bottle\n",
            "Prediction after adv.: saltshaker\n",
            "================10================\n",
            "Original label: Arctic_fox\n",
            "Prediction before adv.: Arctic_fox\n",
            "Prediction after adv.: Samoyed\n",
            "================11================\n",
            "Original label: missile\n",
            "Prediction before adv.: missile\n",
            "Prediction after adv.: projectile\n",
            "================12================\n",
            "Original label: harp\n",
            "Prediction before adv.: harp\n",
            "Prediction after adv.: Brittany_spaniel\n",
            "================13================\n",
            "Original label: bulletproof_vest\n",
            "Prediction before adv.: bulletproof_vest\n",
            "Prediction after adv.: prison\n",
            "================14================\n",
            "Original label: indigo_bunting\n",
            "Prediction before adv.: indigo_bunting\n",
            "Prediction after adv.: European_gallinule\n",
            "================15================\n",
            "Original label: sunscreen\n",
            "Prediction before adv.: sunscreen\n",
            "Prediction after adv.: confectionery\n",
            "================16================\n",
            "Original label: purse\n",
            "Prediction before adv.: purse\n",
            "Prediction after adv.: bulletproof_vest\n",
            "================17================\n",
            "Original label: hair_slide\n",
            "Prediction before adv.: hair_slide\n",
            "Prediction after adv.: bolo_tie\n",
            "================18================\n",
            "Original label: custard_apple\n",
            "Prediction before adv.: custard_apple\n",
            "Prediction after adv.: airliner\n",
            "================19================\n",
            "Original label: beach_wagon\n",
            "Prediction before adv.: beach_wagon\n",
            "Prediction after adv.: minibus\n",
            "================20================\n",
            "Original label: ambulance\n",
            "Prediction before adv.: ambulance\n",
            "Prediction after adv.: police_van\n",
            "================21================\n",
            "Original label: Great_Dane\n",
            "Prediction before adv.: Great_Dane\n",
            "Prediction after adv.: borzoi\n",
            "================22================\n",
            "Original label: spider_monkey\n",
            "Prediction before adv.: spider_monkey\n",
            "Prediction after adv.: orangutan\n",
            "================23================\n",
            "Original label: dugong\n",
            "Prediction before adv.: toyshop\n",
            "Prediction after adv.: toyshop\n",
            "Original label: Italian_greyhound\n",
            "Prediction before adv.: Staffordshire_bullterrier\n",
            "Prediction after adv.: pug\n",
            "Original label: schipperke\n",
            "Prediction before adv.: schipperke\n",
            "Prediction after adv.: soccer_ball\n",
            "================26================\n",
            "Original label: doormat\n",
            "Prediction before adv.: doormat\n",
            "Prediction after adv.: crate\n",
            "================27================\n",
            "Original label: pick\n",
            "Prediction before adv.: doormat\n",
            "Prediction after adv.: doormat\n",
            "Original label: diamondback\n",
            "Prediction before adv.: sidewinder\n",
            "Prediction after adv.: water_snake\n",
            "Original label: brain_coral\n",
            "Prediction before adv.: brain_coral\n",
            "Prediction after adv.: brain_coral\n",
            "================30================\n",
            "Original label: flagpole\n",
            "Prediction before adv.: seashore\n",
            "Prediction after adv.: seashore\n",
            "Original label: scorpion\n",
            "Prediction before adv.: scorpion\n",
            "Prediction after adv.: isopod\n",
            "================32================\n",
            "Original label: lesser_panda\n",
            "Prediction before adv.: lesser_panda\n",
            "Prediction after adv.: aircraft_carrier\n",
            "================33================\n",
            "Original label: rock_python\n",
            "Prediction before adv.: rock_python\n",
            "Prediction after adv.: tiger\n",
            "================34================\n",
            "Original label: Egyptian_cat\n",
            "Prediction before adv.: tabby\n",
            "Prediction after adv.: orange\n",
            "Original label: red-breasted_merganser\n",
            "Prediction before adv.: red-breasted_merganser\n",
            "Prediction after adv.: red-breasted_merganser\n",
            "================36================\n",
            "Original label: standard_poodle\n",
            "Prediction before adv.: standard_poodle\n",
            "Prediction after adv.: cocker_spaniel\n",
            "================37================\n",
            "Original label: miniature_pinscher\n",
            "Prediction before adv.: miniature_pinscher\n",
            "Prediction after adv.: Chihuahua\n",
            "================38================\n",
            "Original label: fiddler_crab\n",
            "Prediction before adv.: fiddler_crab\n",
            "Prediction after adv.: rock_crab\n",
            "================39================\n",
            "Original label: Great_Pyrenees\n",
            "Prediction before adv.: Great_Pyrenees\n",
            "Prediction after adv.: Tibetan_mastiff\n",
            "================40================\n",
            "Original label: tick\n",
            "Prediction before adv.: tick\n",
            "Prediction after adv.: tick\n",
            "================41================\n",
            "Original label: mortarboard\n",
            "Prediction before adv.: mortarboard\n",
            "Prediction after adv.: academic_gown\n",
            "================42================\n",
            "Original label: zebra\n",
            "Prediction before adv.: zebra\n",
            "Prediction after adv.: television\n",
            "================43================\n",
            "Original label: sturgeon\n",
            "Prediction before adv.: sturgeon\n",
            "Prediction after adv.: refrigerator\n",
            "================44================\n",
            "Original label: mongoose\n",
            "Prediction before adv.: mongoose\n",
            "Prediction after adv.: weasel\n",
            "================45================\n",
            "Original label: bustard\n",
            "Prediction before adv.: bustard\n",
            "Prediction after adv.: ostrich\n",
            "================46================\n",
            "Original label: tile_roof\n",
            "Prediction before adv.: palace\n",
            "Prediction after adv.: tobacco_shop\n",
            "Original label: coho\n",
            "Prediction before adv.: coho\n",
            "Prediction after adv.: aircraft_carrier\n",
            "================48================\n",
            "Original label: black_swan\n",
            "Prediction before adv.: black_swan\n",
            "Prediction after adv.: medicine_chest\n",
            "================49================\n",
            "Original label: warthog\n",
            "Prediction before adv.: warthog\n",
            "Prediction after adv.: hyena\n",
            "================50================\n",
            "Original label: harvestman\n",
            "Prediction before adv.: harvestman\n",
            "Prediction after adv.: park_bench\n",
            "================51================\n",
            "Original label: sea_lion\n",
            "Prediction before adv.: sea_lion\n",
            "Prediction after adv.: sea_lion\n",
            "================52================\n",
            "Original label: badger\n",
            "Prediction before adv.: badger\n",
            "Prediction after adv.: Eskimo_dog\n",
            "================53================\n",
            "Original label: syringe\n",
            "Prediction before adv.: microphone\n",
            "Prediction after adv.: microphone\n",
            "Original label: nematode\n",
            "Prediction before adv.: nematode\n",
            "Prediction after adv.: vault\n",
            "================55================\n",
            "Original label: submarine\n",
            "Prediction before adv.: submarine\n",
            "Prediction after adv.: swing\n",
            "================56================\n",
            "Original label: jinrikisha\n",
            "Prediction before adv.: jinrikisha\n",
            "Prediction after adv.: jinrikisha\n",
            "================57================\n",
            "Original label: disk_brake\n",
            "Prediction before adv.: disk_brake\n",
            "Prediction after adv.: Pekinese\n",
            "================58================\n",
            "Original label: ice_lolly\n",
            "Prediction before adv.: candle\n",
            "Prediction after adv.: candle\n",
            "Original label: EntleBucher\n",
            "Prediction before adv.: EntleBucher\n",
            "Prediction after adv.: Appenzeller\n",
            "================60================\n",
            "Original label: grille\n",
            "Prediction before adv.: grille\n",
            "Prediction after adv.: convertible\n",
            "================61================\n",
            "Original label: oxcart\n",
            "Prediction before adv.: oxcart\n",
            "Prediction after adv.: worm_fence\n",
            "================62================\n",
            "Original label: Pembroke\n",
            "Prediction before adv.: Cardigan\n",
            "Prediction after adv.: Walker_hound\n",
            "Original label: briard\n",
            "Prediction before adv.: Appenzeller\n",
            "Prediction after adv.: Appenzeller\n",
            "Original label: toilet_tissue\n",
            "Prediction before adv.: toilet_tissue\n",
            "Prediction after adv.: paper_towel\n",
            "================65================\n",
            "Original label: menu\n",
            "Prediction before adv.: menu\n",
            "Prediction after adv.: bath_towel\n",
            "================66================\n",
            "Original label: planetarium\n",
            "Prediction before adv.: planetarium\n",
            "Prediction after adv.: dome\n",
            "================67================\n",
            "Original label: streetcar\n",
            "Prediction before adv.: streetcar\n",
            "Prediction after adv.: hoopskirt\n",
            "================68================\n",
            "Original label: great_white_shark\n",
            "Prediction before adv.: great_white_shark\n",
            "Prediction after adv.: tiger_shark\n",
            "================69================\n",
            "Original label: letter_opener\n",
            "Prediction before adv.: letter_opener\n",
            "Prediction after adv.: hammer\n",
            "================70================\n",
            "Original label: rocking_chair\n",
            "Prediction before adv.: rocking_chair\n",
            "Prediction after adv.: stretcher\n",
            "================71================\n",
            "Original label: bucket\n",
            "Prediction before adv.: nail\n",
            "Prediction after adv.: nail\n",
            "Original label: earthstar\n",
            "Prediction before adv.: earthstar\n",
            "Prediction after adv.: earthstar\n",
            "================73================\n",
            "Original label: basenji\n",
            "Prediction before adv.: basenji\n",
            "Prediction after adv.: acorn\n",
            "================74================\n",
            "Original label: golden_retriever\n",
            "Prediction before adv.: golden_retriever\n",
            "Prediction after adv.: Labrador_retriever\n",
            "================75================\n",
            "Original label: partridge\n",
            "Prediction before adv.: partridge\n",
            "Prediction after adv.: ruffed_grouse\n",
            "================76================\n",
            "Original label: paddle\n",
            "Prediction before adv.: canoe\n",
            "Prediction after adv.: canoe\n",
            "Original label: CD_player\n",
            "Prediction before adv.: Polaroid_camera\n",
            "Prediction after adv.: printer\n",
            "Original label: window_screen\n",
            "Prediction before adv.: window_screen\n",
            "Prediction after adv.: seashore\n",
            "================79================\n",
            "Original label: hourglass\n",
            "Prediction before adv.: hourglass\n",
            "Prediction after adv.: hourglass\n",
            "================80================\n",
            "Original label: microwave\n",
            "Prediction before adv.: microwave\n",
            "Prediction after adv.: meerkat\n",
            "================81================\n",
            "Original label: cheeseburger\n",
            "Prediction before adv.: cheeseburger\n",
            "Prediction after adv.: umbrella\n",
            "================82================\n",
            "Original label: radio\n",
            "Prediction before adv.: radio\n",
            "Prediction after adv.: cassette_player\n",
            "================83================\n",
            "Original label: snowmobile\n",
            "Prediction before adv.: snowmobile\n",
            "Prediction after adv.: Dandie_Dinmont\n",
            "================84================\n",
            "Original label: modem\n",
            "Prediction before adv.: modem\n",
            "Prediction after adv.: radio\n",
            "================85================\n",
            "Original label: desk\n",
            "Prediction before adv.: desktop_computer\n",
            "Prediction after adv.: desktop_computer\n",
            "Original label: tiger\n",
            "Prediction before adv.: tiger\n",
            "Prediction after adv.: obelisk\n",
            "================87================\n",
            "Original label: pick\n",
            "Prediction before adv.: pick\n",
            "Prediction after adv.: necklace\n",
            "================88================\n",
            "Original label: English_springer\n",
            "Prediction before adv.: Border_collie\n",
            "Prediction after adv.: Border_collie\n",
            "Original label: acoustic_guitar\n",
            "Prediction before adv.: canoe\n",
            "Prediction after adv.: speedboat\n",
            "Original label: soft-coated_wheaten_terrier\n",
            "Prediction before adv.: soft-coated_wheaten_terrier\n",
            "Prediction after adv.: otterhound\n",
            "================91================\n",
            "Original label: warplane\n",
            "Prediction before adv.: warplane\n",
            "Prediction after adv.: aircraft_carrier\n",
            "================92================\n",
            "Original label: grocery_store\n",
            "Prediction before adv.: grocery_store\n",
            "Prediction after adv.: head_cabbage\n",
            "================93================\n",
            "Original label: leatherback_turtle\n",
            "Prediction before adv.: loggerhead\n",
            "Prediction after adv.: loggerhead\n",
            "Original label: papillon\n",
            "Prediction before adv.: papillon\n",
            "Prediction after adv.: Blenheim_spaniel\n",
            "================95================\n",
            "Original label: lab_coat\n",
            "Prediction before adv.: lab_coat\n",
            "Prediction after adv.: grocery_store\n",
            "================96================\n",
            "Original label: Siamese_cat\n",
            "Prediction before adv.: Siamese_cat\n",
            "Prediction after adv.: bib\n",
            "================97================\n",
            "Original label: Saint_Bernard\n",
            "Prediction before adv.: Saint_Bernard\n",
            "Prediction after adv.: Brittany_spaniel\n",
            "================98================\n",
            "Original label: European_fire_salamander\n",
            "Prediction before adv.: European_fire_salamander\n",
            "Prediction after adv.: spotted_salamander\n",
            "================99================\n",
            "Total correct predictions: 79\n",
            "Total successful attacks: 72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsulTAbhhlQK"
      },
      "source": [
        "f = open(\"pgd_losses_bit.pkl\", \"wb\")\n",
        "f.write(pickle.dumps(all_losses))\n",
        "f.close()"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}